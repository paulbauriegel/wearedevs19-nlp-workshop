{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teach a machine to understand human language\n",
    "##### WeAreDeveloper World Congress 2019\n",
    "\n",
    "## Part 1 - Natural Language Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some imports we maybe need afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look into the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/paul/Downloads/classifier_dataset.csv\"\n",
    "df = pd.read_csv(path, encoding=\"utf-8\", header=0, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Like many AUX, the Lombard has S or Lombards</td>\n",
       "      <td>devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is there still the Monaco 1?</td>\n",
       "      <td>devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Show me Comfort Pro P 500 devices</td>\n",
       "      <td>devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>which connection options does the Ergotel s ha...</td>\n",
       "      <td>devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Show me all the colors for the Actron Card</td>\n",
       "      <td>devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I&amp;#39;m looking for a garnet 1 phone</td>\n",
       "      <td>devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Which SIM card is in the Google Pixel?</td>\n",
       "      <td>devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is the purchase price for speedort W724 v</td>\n",
       "      <td>devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What weighs a Samsung phone?</td>\n",
       "      <td>devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is the bottom line between the Google Pix...</td>\n",
       "      <td>devices</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question      cat\n",
       "0       Like many AUX, the Lombard has S or Lombards  devices\n",
       "1                       Is there still the Monaco 1?  devices\n",
       "2                  Show me Comfort Pro P 500 devices  devices\n",
       "3  which connection options does the Ergotel s ha...  devices\n",
       "4         Show me all the colors for the Actron Card  devices\n",
       "5               I&#39;m looking for a garnet 1 phone  devices\n",
       "6             Which SIM card is in the Google Pixel?  devices\n",
       "7     What is the purchase price for speedort W724 v  devices\n",
       "8                       What weighs a Samsung phone?  devices\n",
       "9  What is the bottom line between the Google Pix...  devices"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features from the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different approaches:\n",
    "- Bag-of-words model\n",
    "- Latent Semantic Indexing\n",
    "- Latent Dirchlet Allocation\n",
    "- Word Embeddings (Word2Vec, Glove, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a simple bag of words model for this purpose. And for that we need a matrix of the words and their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train['question'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can already apply a machine learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_counts, train['cat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there still the Monaco 1? - devices\n"
     ]
    }
   ],
   "source": [
    "mat = count_vect.transform([test['question'][1]])\n",
    "res = clf.predict(mat)\n",
    "print(test['question'][1], '-' ,res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     devices       0.94      0.72      0.82        90\n",
      "   processes       0.61      0.85      0.71        27\n",
      "   smarthome       0.76      1.00      0.86        32\n",
      "     tariffs       0.84      0.84      0.84        73\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       222\n",
      "   macro avg       0.79      0.85      0.81       222\n",
      "weighted avg       0.84      0.82      0.82       222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "mat = count_vect.transform(test['question'])\n",
    "res = clf.predict(mat)\n",
    "np.mean(res == test['cat'])\n",
    "accuracy_score(res, test['cat'])\n",
    "print(classification_report(res, test['cat']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make that a bit simpler, so that we can work with better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8153153153153153"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('clf', MultinomialNB())])\n",
    "text_clf = text_clf.fit(train['question'], train['cat'])\n",
    "predicted = text_clf.predict(test['question'])\n",
    "np.mean(predicted == test['cat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Optimisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TF-IDF\n",
    "- Stopwords\n",
    "- Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term Frequency â€” Inverse Data Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Term Frequency (TF)* - how often a word appears in a document, divided by how many words there are<br>\n",
    "$\\mathit{tf}_{t, d}=\\frac{\\textrm{number of occurences in document}}{\\textrm{total number of all words in document}}$\n",
    "\n",
    "*Inverse document frequency (IDF)* - is how unique or rare a word is<br>\n",
    "$\\mathit{idf}_{t, d}=\\log{\\frac{\\textrm{times term t appears}}{\\textrm{number of documents containing term t}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7207207207207207"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "\n",
    "text_clf = text_clf.fit(train['question'], train['cat'])\n",
    "predicted = text_clf.predict(test['question'])\n",
    "np.mean(predicted == test['cat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*_OsV8gO2cjy9qcFhrtCdiw.jpeg\" alt=\"Stopwords\" style=\"width: 400px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the      661\n",
       "is       286\n",
       "how      243\n",
       "what     198\n",
       "which    193\n",
       "of       177\n",
       "does     163\n",
       "with     163\n",
       "for      158\n",
       "in       155\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = list(df[\"question\"])\n",
    "X = count_vect.fit_transform(txt)\n",
    "pd.DataFrame(X.A, columns=count_vect.get_feature_names()).sum().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ENGLISH_STOP_WORDS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-99b3a2785f33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcount_vect_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mENGLISH_STOP_WORDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vect_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount_vect_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ENGLISH_STOP_WORDS' is not defined"
     ]
    }
   ],
   "source": [
    "txt = list(df[\"question\"])\n",
    "count_vect_stop = CountVectorizer(stop_words=ENGLISH_STOP_WORDS)\n",
    "X = count_vect_stop.fit_transform(txt)\n",
    "pd.DataFrame(X.A, columns=count_vect_stop.get_feature_names()).sum().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7567567567567568"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words=ENGLISH_STOP_WORDS)), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "\n",
    "text_clf = text_clf.fit(train['question'], train['cat'])\n",
    "predicted = text_clf.predict(test['question'])\n",
    "np.mean(predicted == test['cat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Regex Preprocessing of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39      19\n",
       "415     17\n",
       "10       9\n",
       "400      7\n",
       "2nd      6\n",
       "s7       6\n",
       "a3       6\n",
       "64gb     5\n",
       "806      4\n",
       "724v     4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = list(df[\"question\"])\n",
    "count_vect_stop = CountVectorizer(stop_words=ENGLISH_STOP_WORDS)\n",
    "X = count_vect_stop.fit_transform(txt)\n",
    "pd.DataFrame(X.A, columns=count_vect_stop.get_feature_names()).sum().sort_values(ascending=False).filter(regex='.*\\d.*')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7612612612612613"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(\n",
    "        stop_words='english', \n",
    "        preprocessor=lambda x: re.sub(r'(\\d[\\d\\.])+', 'NUM', x.lower())\n",
    "    )), \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('clf', MultinomialNB())])\n",
    "\n",
    "text_clf = text_clf.fit(train['question'], train['cat'])\n",
    "predicted = text_clf.predict(test['question'])\n",
    "np.mean(predicted == test['cat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Stemming](https://1.bp.blogspot.com/-s5VGFbL8-ew/W5wSySqBbYI/AAAAAAAABdw/elNHb72ki2oTRgUORGXzhTBMfBk-oa08gCEwYBhgL/s1600/image003.png)\n",
    "There are multiple different stemming algorithms: Porter, Snowball(Porter2), and Lancaster (Paice-Husk). For the english langauge The Snowball stemmer usually a good choice, but you can test the others as well. We are using an the implementation from NLTK. For a description of the algortihm: [Link](https://snowballstem.org/algorithms/porter/stemmer.html)\n",
    "\n",
    "Some terminology on Stemming vs Lemmatization: The derived root word (lemma) of a Lemmatization is always a lexicographically correct word, the root stem may be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/paul/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/paul/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7927927927927928"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', StemmedCountVectorizer(\n",
    "        stop_words=ENGLISH_STOP_WORDS, \n",
    "        preprocessor=lambda x: re.sub(r'(\\d[\\d\\.])+', 'NUM', x.lower())\n",
    "    )), \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('clf', MultinomialNB())])\n",
    "\n",
    "text_clf = text_clf.fit(train['question'], train['cat'])\n",
    "predicted = text_clf.predict(test['question'])\n",
    "np.mean(predicted == test['cat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Optimisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variant 1: Using hyperparameter optimization\n",
    "\n",
    "For example by using Exhaustive Grid Search - Basically Brute Force Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.01,\n",
       " 'clf__fit_prior': True,\n",
       " 'tfidf__use_idf': True,\n",
       " 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', StemmedCountVectorizer(\n",
    "        stop_words=ENGLISH_STOP_WORDS, \n",
    "        preprocessor=lambda x: re.sub(r'(\\d[\\d\\.])+', 'NUM', x.lower())\n",
    "    )), \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('clf', MultinomialNB())])\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__fit_prior': (True, False),\n",
    "              'clf__alpha': (1e-3, 1e-2,0.5, 1)\n",
    "}\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=1) # Because of Anaconda\n",
    "gs_clf = gs_clf.fit(train['question'], train['cat'])\n",
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8513513513513513"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', StemmedCountVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words=ENGLISH_STOP_WORDS, \n",
    "        preprocessor=lambda x: re.sub(r'(\\d[\\d\\.])+', 'NUM', x.lower())\n",
    "    )), \n",
    "    ('tfidf', TfidfTransformer(use_idf=True)), \n",
    "    ('clf', MultinomialNB(fit_prior=False, alpha=1e-2))])\n",
    "\n",
    "text_clf = text_clf.fit(train['question'], train['cat'])\n",
    "predicted = text_clf.predict(test['question'])\n",
    "np.mean(predicted == test['cat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variant 2: Try other algorithms\n",
    "\n",
    "For example by using Exhaustive Grid Search - Basically Brute Force Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
